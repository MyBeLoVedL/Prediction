{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Sentiment Analysis using News Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Data.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Date     0\nLabel    0\nTop1     0\nTop2     0\nTop3     0\nTop4     0\nTop5     0\nTop6     0\nTop7     0\nTop8     0\nTop9     0\nTop10    0\nTop11    0\nTop12    0\nTop13    0\nTop14    0\nTop15    0\nTop16    0\nTop17    0\nTop18    0\nTop19    0\nTop20    0\nTop21    0\nTop22    0\nTop23    1\nTop24    3\nTop25    3\ndtype: int64"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set({})\n",
    "with open('stopwords','r') as f:\n",
    "\tfor line in f:\n",
    "\t\tstop_words.add(line.strip())\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-36-75c4564ad5a4>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Top23'][index] = df['Top1'][index]\n",
      "<ipython-input-36-75c4564ad5a4>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Top24'][index] = df['Top1'][index]\n",
      "<ipython-input-36-75c4564ad5a4>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Top25'][index] = df['Top1'][index]\n"
     ]
    },
    {
     "data": {
      "text/plain": "Date     0\nLabel    0\nTop1     0\nTop2     0\nTop3     0\nTop4     0\nTop5     0\nTop6     0\nTop7     0\nTop8     0\nTop9     0\nTop10    0\nTop11    0\nTop12    0\nTop13    0\nTop14    0\nTop15    0\nTop16    0\nTop17    0\nTop18    0\nTop19    0\nTop20    0\nTop21    0\nTop22    0\nTop23    0\nTop24    0\nTop25    0\ndtype: int64"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = df['Top23'].index\n",
    "df['Top23'][index] = df['Top1'][index]\n",
    "\n",
    "index = df['Top24'].index\n",
    "df['Top24'][index] = df['Top1'][index]\n",
    "\n",
    "\n",
    "index = df['Top25'].index\n",
    "df['Top25'][index] = df['Top1'][index]\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'a hindrance operations extracts leaked reports scorecard hughes instant hit buoys blues jack gets skates icecold alex chaos maracana builds united depleted leicester prevail elliott spoils evertons party hungry spurs sense rich pickings gunners wide easy target derby raise glass strupars debut double southgate strikes leeds pay penalty hammers hand robson youthful lesson saints party like wear wolves turned lambs stump mike catches testy goughs taunt langer escapes hit flintoff injury piles woe england hunters threaten jospin new battle somme kohls successor drawn scandal the difference men women sara denver nurse turned solicitor dianas landmine crusade put tories panic yeltsins resignation caught opposition flatfooted a hindrance operations extracts leaked reports a hindrance operations extracts leaked reports a hindrance operations extracts leaked reports'"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re_obj = re.compile(r'[^a-zA-Z ]')\n",
    "row_string = []\n",
    "\n",
    "\n",
    "for i in range(len(df.index)):\n",
    "\trow_string.append(' '.join(top for top in df.iloc[i,2:]))\n",
    "for i,_ in enumerate(row_string):\n",
    "\t# row_string[i].replace(r'[^a-zA-Z]','',regex = True,inplace=True)\n",
    "\trow_string[i] =  re_obj.sub('',row_string[i])\n",
    "\trow_string[i] = row_string[i].lower()\n",
    "row_string[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'A hindrance operations extracts leaked reports Scorecard Hughes instant hit buoys Blues Jack gets skates icecold Alex Chaos Maracana builds United Depleted Leicester prevail Elliott spoils Evertons party Hungry Spurs sense rich pickings Gunners wide easy target Derby raise glass Strupars debut double Southgate strikes Leeds pay penalty Hammers hand Robson youthful lesson Saints party like Wear wolves turned lambs Stump mike catches testy Goughs taunt Langer escapes hit Flintoff injury piles woe England Hunters threaten Jospin new battle Somme Kohls successor drawn scandal The difference men women Sara Denver nurse turned solicitor Dianas landmine crusade put Tories panic Yeltsins resignation caught opposition flatfooted A hindrance operations extracts leaked reports A hindrance operations extracts leaked reports A hindrance operations extracts leaked reports'"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stop(sentence : str):\n",
    "\twords = sentence.split()\n",
    "\treturn ' '.join([word  for word in words if word not in stop_words])\n",
    "\n",
    "\n",
    "for i,s in enumerate(row_string):\n",
    "\trow_string[i] = remove_stop(row_string[i])\n",
    "\n",
    "row_string[0]\n",
    "\n",
    "# \tdf.iloc[:,2 + i] = df.iloc[:,2 + i].map(remove_stop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Label</th>\n      <th>Content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2000-01-03</td>\n      <td>0</td>\n      <td>a hindrance operations extracts leaked reports...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2000-01-04</td>\n      <td>0</td>\n      <td>scorecard the best lake scene leader german sl...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2000-01-05</td>\n      <td>0</td>\n      <td>coventry caught counter flo uniteds rivals roa...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2000-01-06</td>\n      <td>1</td>\n      <td>pilgrim knows progress thatcher facing ban mci...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2000-01-07</td>\n      <td>1</td>\n      <td>hitches horlocks beckham united survive breast...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "         Date  Label                                            Content\n0  2000-01-03      0  a hindrance operations extracts leaked reports...\n1  2000-01-04      0  scorecard the best lake scene leader german sl...\n2  2000-01-05      0  coventry caught counter flo uniteds rivals roa...\n3  2000-01-06      1  pilgrim knows progress thatcher facing ban mci...\n4  2000-01-07      1  hitches horlocks beckham united survive breast..."
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Top1'] = pd.Series(row_string)\n",
    "df = df[['Date','Label','Top1']]\n",
    "df.columns = ['Date','Label','Content']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df['Date'] < '20150101']\n",
    "test = df[df['Date'] > '20141231']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = list(train['Content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## implement BAG OF WORDS\n",
    "countvector=CountVectorizer(ngram_range=(2,2))\n",
    "traindataset=countvector.fit_transform(headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier(criterion='entropy', n_estimators=200)"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implement RandomForest Classifier\n",
    "randomclassifier=RandomForestClassifier(n_estimators=200,criterion='entropy')\n",
    "randomclassifier.fit(traindataset,train['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict for the Test Dataset\n",
    "test_transform= test['Content']\n",
    "test_dataset = countvector.transform(test_transform)\n",
    "predictions = randomclassifier.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import library to check accuracy\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[131  55]\n",
      " [  2 190]]\n",
      "0.8492063492063492\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.70      0.82       186\n",
      "           1       0.78      0.99      0.87       192\n",
      "\n",
      "    accuracy                           0.85       378\n",
      "   macro avg       0.88      0.85      0.85       378\n",
      "weighted avg       0.88      0.85      0.85       378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matrix=confusion_matrix(test['Label'],predictions)\n",
    "print(matrix)\n",
    "score=accuracy_score(test['Label'],predictions)\n",
    "print(score)\n",
    "report=classification_report(test['Label'],predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier, SGDRegressor,LogisticRegression\n",
    "\n",
    "basicmodel = LogisticRegression()\n",
    "basicmodel = basicmodel.fit(traindataset, train[\"Label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logic regression [0.8333333333333334]\n"
     ]
    }
   ],
   "source": [
    "preds1 = basicmodel.predict(test_dataset)\n",
    "\n",
    "acc1=accuracy_score(test['Label'], preds1)\n",
    "print(f'logic regression [{acc1}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * naive beyes \n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "advancedvectorizer = TfidfVectorizer( min_df=0.1, max_df=0.7, max_features = 200000, ngram_range = (1, 1))\n",
    "advancedtrain = advancedvectorizer.fit_transform(headlines)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive beyes :  [0.5185185185185185]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "advancedmodel = MultinomialNB(alpha=0.01)\n",
    "advancedmodel = advancedmodel.fit(advancedtrain, train[\"Label\"])\n",
    "testheadlines = []\n",
    "for row in range(0,len(test.index)):\n",
    "    testheadlines.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n",
    "advancedtest = advancedvectorizer.transform(testheadlines)\n",
    "preds4 = advancedmodel.predict(advancedtest)\n",
    "acc2=accuracy_score(test['Label'], preds4)\n",
    "print(f'naive beyes :  [{acc2}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gradient boosting machine\n",
    "\n",
    "advancedvectorizer = TfidfVectorizer( min_df=0.1, max_df=0.9, max_features = 200000, ngram_range = (1, 1))\n",
    "advancedtrain = advancedvectorizer.fit_transform(headlines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive beyes :  [0.671957671957672]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "advancedmodel = GradientBoostingClassifier()\n",
    "advancedmodel = advancedmodel.fit(advancedtrain, train[\"Label\"])\n",
    "testheadlines = []\n",
    "for row in range(0,len(test.index)):\n",
    "    testheadlines.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n",
    "advancedtest = advancedvectorizer.transform(testheadlines)\n",
    "preds8 = advancedmodel.predict(advancedtest.toarray())\n",
    "acc3 = accuracy_score(test['Label'], preds8)\n",
    "\n",
    "print(f'naive beyes :  [{acc3}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "advancedvectorizer = TfidfVectorizer( min_df=0.2, max_df=0.8, max_features = 200000, ngram_range = (1, 1))\n",
    "advancedtrain = advancedvectorizer.fit_transform(headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD :  :  [0.5476190476190477]\n"
     ]
    }
   ],
   "source": [
    "# stochastic gradient descent   \n",
    "\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier, SGDRegressor,LogisticRegression\n",
    "\n",
    "advancedmodel = SGDClassifier(loss='modified_huber',random_state=0, shuffle=True)\n",
    "advancedmodel = advancedmodel.fit(advancedtrain, train[\"Label\"])\n",
    "testheadlines = []\n",
    "for row in range(0,len(test.index)):\n",
    "    testheadlines.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n",
    "advancedtest = advancedvectorizer.transform(testheadlines)\n",
    "preds10 = advancedmodel.predict(advancedtest.toarray())\n",
    "acc4 = accuracy_score(test['Label'], preds10)\n",
    "\n",
    "\n",
    "print(f'SGD :  :  [{acc4}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param = {\n",
    "\t'n_neighbors' : [5,7],\n",
    "\t'weights':['uniform','distance'],\n",
    "\t'p' : [2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": "GridSearchCV(cv=2, estimator=KNeighborsClassifier(), n_jobs=-1,\n             param_grid={'n_neighbors': [5, 7], 'p': [2],\n                         'weights': ['uniform', 'distance']},\n             scoring='f1', verbose=10)"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(estimator=KNeighborsClassifier(),param_grid=param,cv=2,scoring='f1',n_jobs=-1,verbose=10)\n",
    "gs.fit(advancedtrain,train['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN :  [0.6296296296296297]\n"
     ]
    }
   ],
   "source": [
    "advancedtest = advancedvectorizer.transform(testheadlines)\n",
    "preds6 = gs.predict(advancedtest)\n",
    "\n",
    "\n",
    "acc6=accuracy_score(test['Label'], preds6)\n",
    "print(f'KNN :  [{acc6}]')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}